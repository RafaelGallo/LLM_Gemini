{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo LLM Gemini avançado**"
      ],
      "metadata": {
        "id": "nx6-S2qO-v8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "LBmJab5z-mrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar recursos do NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "2CSKz9tZAKPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar modelo do SpaCy para lematização\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "g71q3miPANPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base dados\n",
        "df = pd.read_csv(\"/content/financial_phrase_bank_pt_br.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "WlqK4vR4_COs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando 5 primeiros dados\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Lah0gOBu_F7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando 5 últimos dados\n",
        "df.info()"
      ],
      "metadata": {
        "id": "xOni3NUM_G8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tipo dados\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "O7F4oMfG_Jce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linhas e colunas\n",
        "df.shape"
      ],
      "metadata": {
        "id": "zL6NArx7_Kc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora, vamos renomear as colunas\n",
        "df = df.rename(columns={\"y\": \"Sentimento\",\n",
        "                        \"text\": \"Text\",\n",
        "                        \"text_pt\": \"Text_pt\"})\n",
        "\n",
        "# Visualizar o DataFrame com as colunas renomeadas\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Lj_uX_K5_NpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pré-processamento**"
      ],
      "metadata": {
        "id": "-csmbBXK_0ZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para limpar o texto\n",
        "\n",
        "def limpar_texto(texto):\n",
        "    # Converter para minúsculas\n",
        "    texto = texto.lower()\n",
        "    # Remover caracteres especiais, números e pontuações\n",
        "    texto = re.sub(r'[^a-zA-Z\\s]', '', texto)\n",
        "    # Remover espaços em branco extras\n",
        "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
        "    return texto\n",
        "\n",
        "# Função para remover stop words\n",
        "def remover_stop_words(texto):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    palavras = word_tokenize(texto)\n",
        "    texto_sem_stopwords = [word for word in palavras if word not in stop_words]\n",
        "    return ' '.join(texto_sem_stopwords)\n",
        "\n",
        "# Função para lematizar o texto\n",
        "def lematizar_texto(texto):\n",
        "    doc = nlp(texto)\n",
        "    texto_lematizado = \" \".join([token.lemma_ for token in doc])\n",
        "    return texto_lematizado\n",
        "\n",
        "# Aplicar as funções de pré-processamento à coluna \"Text\" e criar a coluna \"Texto_limpo\"\n",
        "df['Texto_limpo'] = df['Text'].apply(limpar_texto)\n",
        "df['Texto_limpo'] = df['Texto_limpo'].apply(remover_stop_words)\n",
        "df['Texto_limpo'] = df['Texto_limpo'].apply(lematizar_texto)"
      ],
      "metadata": {
        "id": "wVyU_OCH_8Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualiznado\n",
        "df.head()"
      ],
      "metadata": {
        "id": "5wXKxplm_8Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando nova coluna\n",
        "df.Texto_limpo.head()"
      ],
      "metadata": {
        "id": "08Gyjast_8Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Análise dados**"
      ],
      "metadata": {
        "id": "zKMgzVCl_5g_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='Sentimento', data=df)\n",
        "plt.title('Distribuição de Sentimentos')\n",
        "plt.xlabel('Sentimento')\n",
        "plt.ylabel('Quantidade')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mvQM2P6z_Z-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Juntar todas as palavras em uma única string\n",
        "texto_completo = ' '.join(df['Text'])\n",
        "\n",
        "# Criar a nuvem de palavras\n",
        "wordcloud = WordCloud(width=800, height=400, background_color ='white').generate(texto_completo)\n",
        "\n",
        "# Plotar a nuvem de palavras\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.title('Nuvem de Palavras - Texto geral')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U4oPzBZ__yU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Juntar todas as palavras em uma única string\n",
        "texto_completo = ' '.join(df['Texto_limpo'])\n",
        "\n",
        "# Criar a nuvem de palavras\n",
        "wordcloud = WordCloud(width=800, height=400, background_color ='white').generate(texto_completo)\n",
        "\n",
        "# Plotar a nuvem de palavras\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.title('Nuvem de Palavras - Texto limpo')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gT1hF7IkBCwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar o DataFrame por cada sentimento\n",
        "sentimentos_unicos = df['Sentimento'].unique()\n",
        "\n",
        "# Criar uma nuvem de palavras para cada sentimento\n",
        "for sentimento in sentimentos_unicos:\n",
        "\n",
        "    # Filtrar o texto limpo para o sentimento atual\n",
        "    texto_completo = ' '.join(df[df['Sentimento'] == sentimento]['Texto_limpo'])\n",
        "\n",
        "    # Criar a nuvem de palavras\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color ='white').generate(texto_completo)\n",
        "\n",
        "    # Plotar a nuvem de palavras\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.title(sentimento)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4YPfn6cBBEsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenização texto\n",
        "\n",
        "# Função para tokenizar o texto\n",
        "def tokenizar_texto(texto):\n",
        "    tokens = word_tokenize(texto)\n",
        "    return tokens\n",
        "\n",
        "# Aplicar a função de tokenização à coluna \"Text\"\n",
        "df['text_Tokens'] = df['Text'].apply(tokenizar_texto)"
      ],
      "metadata": {
        "id": "FDWd7dQIBfJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando os tokens\n",
        "df.text_Tokens"
      ],
      "metadata": {
        "id": "rFjYzBFGBw4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar a frequência de cada token\n",
        "tokens_freq = pd.Series([token for sublist in df['text_Tokens'] for token in sublist]).value_counts()\n",
        "\n",
        "# Plotar o gráfico de barras com seaborn\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x=tokens_freq.index[:20], y=tokens_freq.values[:20])\n",
        "plt.title('Top 20 Tokens')\n",
        "plt.xlabel('Token')\n",
        "plt.ylabel('Frequência')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_3IYYsmVBfMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função n_grams\n",
        "\n",
        "# Importando biblioteca\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "\n",
        "# Função para criar n-grams\n",
        "def criar_ngrams(tokens, n):\n",
        "    ngrams_list = list(ngrams(tokens, n))\n",
        "    return ngrams_list\n",
        "\n",
        "# Aplicar a função de criação de n-grams à coluna \"Tokens\"\n",
        "df['Ngrams'] = df['text_Tokens'].apply(lambda x: criar_ngrams(x, 2))  # Exemplo de criação de bigrams (n=2)\n",
        "\n",
        "# Contar a frequência de cada n-gram\n",
        "ngrams_freq = Counter([gram for sublist in df['Ngrams'] for gram in sublist])\n",
        "\n",
        "# Exibir os 10 n-grams mais frequentes\n",
        "print(ngrams_freq.most_common(10))"
      ],
      "metadata": {
        "id": "kYQQirSMBfO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrair as palavras dos n-grams\n",
        "words = [word for sublist in df['Ngrams'] for gram in sublist for word in gram]\n",
        "\n",
        "# Contar a frequência das palavras\n",
        "word_freq = Counter(words)\n",
        "\n",
        "# Converter o resultado do contador em um DataFrame pandas\n",
        "df_word_freq = pd.DataFrame.from_dict(word_freq, orient='index').reset_index()\n",
        "df_word_freq.columns = ['Palavra', 'Frequência']\n",
        "\n",
        "# Ordenar o DataFrame por frequência\n",
        "df_word_freq = df_word_freq.sort_values(by='Frequência', ascending=False)\n",
        "df_word_freq"
      ],
      "metadata": {
        "id": "joNUNjwtCyu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenar o DataFrame por frequência\n",
        "df_word_freq = df_word_freq.sort_values(by='Frequência', ascending=False)\n",
        "\n",
        "# Plotar o gráfico de barras com Seaborn\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x='Frequência', y='Palavra', data=df_word_freq.head(25), color='skyblue', edgecolor='black')\n",
        "plt.title('Top 25 Palavras dos N-grams')\n",
        "plt.xlabel('Frequência')\n",
        "plt.ylabel('Palavra')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y233whCJBfRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão treino e teste\n",
        "x = df['Texto_limpo']\n",
        "y = df['Sentimento']"
      ],
      "metadata": {
        "id": "8QokM0DNDUtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando linhas e colunas x\n",
        "x.shape"
      ],
      "metadata": {
        "id": "q3QBRp-xDssZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando linhas e colunas y\n",
        "y.shape"
      ],
      "metadata": {
        "id": "na9Als3qDv-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotca\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Vetorização dos textos usando TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Treinamento\n",
        "X = vectorizer.fit_transform(x)\n",
        "\n",
        "# Visualizando\n",
        "vectorizer"
      ],
      "metadata": {
        "id": "99dL3HjREjVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando biblioteca\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Instanciando o PCA\n",
        "# Redução de dimensionalidade com PCA para visualização\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Treinamento modelo\n",
        "X_pca = pca.fit_transform(X.toarray())\n",
        "\n",
        "# Visualizando\n",
        "pca"
      ],
      "metadata": {
        "id": "Mg1wCsU7EjYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Calcular a inércia para diferentes números de clusters\n",
        "inertia = []\n",
        "for i in range(1, 20):\n",
        "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
        "    kmeans.fit(X)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Plotar a curva de cotovelo (elbow)\n",
        "plt.plot(range(1, 20), inertia, marker='o')\n",
        "plt.xlabel('Número de Clusters')\n",
        "plt.ylabel('Inércia')\n",
        "plt.title('Método do Cotovelo para Determinar Número de Clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GDebiBpyEjbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escolher o número de clusters\n",
        "# Defina o número de clusters com base no método do cotovelo\n",
        "num_clusters = 5"
      ],
      "metadata": {
        "id": "dM2Y-kEZFr7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar e ajustar o modelo K-means com o número de clusters escolhido\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "clusters = kmeans.fit_predict(X)"
      ],
      "metadata": {
        "id": "Jywh_yMRFsAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicionar os clusters ao DataFrame\n",
        "df['Cluster_kemans'] = clusters"
      ],
      "metadata": {
        "id": "qyL9dpq_FsDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização dos clusters\n",
        "# Redução de dimensionalidade com PCA para visualização\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Treinamento modelo\n",
        "X_pca = pca.fit_transform(X.toarray())\n",
        "\n",
        "# Visualizando\n",
        "pca"
      ],
      "metadata": {
        "id": "aVZxY8hMFsF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização dos clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "scatter = plt.scatter(X_pca[:, 0],\n",
        "                      X_pca[:, 1],\n",
        "                      c=clusters)\n",
        "\n",
        "plt.xlabel('Componente Principal 1')\n",
        "plt.ylabel('Componente Principal 2')\n",
        "plt.title('Clusterização dos Textos - Kmeans')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R_Bo65s8F1KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modelo LLM Gemini**"
      ],
      "metadata": {
        "id": "aU8Vp-U8EIZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "k_ucseG9Dyw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando driver\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "u_nIroDZGOwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Certifique-se de que a GPU está disponível\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "3xU10guXGO1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mover o modelo para o dispositivo correto para GPU\n",
        "model = model.to(device)\n",
        "model"
      ],
      "metadata": {
        "id": "UTERxSPxIZM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "myIm4VyMMkq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotca\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Vetorização dos textos usando TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Treinamento\n",
        "train = vectorizer.fit_transform(x)\n",
        "\n",
        "# Visualizando\n",
        "vectorizer"
      ],
      "metadata": {
        "id": "4ki3yMDwJsyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenização dos texto\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"describeai/gemini\")"
      ],
      "metadata": {
        "id": "EnK8SYehEQUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo LLM Gemini\n",
        "\n",
        "# Carregar o tokenizador e o modelo\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"describeai/gemini\")"
      ],
      "metadata": {
        "id": "C7Z5t18PESO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para armazenar os textos gerados\n",
        "textos_gerados = []\n",
        "epocas = []\n",
        "\n",
        "# Número total de épocas\n",
        "total_epocas = len(df)\n",
        "print(\"Número total de épocas:\", total_epocas)"
      ],
      "metadata": {
        "id": "biZCYd70JEcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop sobre os primeiros 100 textos limpos\n",
        "for i, texto_limpo in enumerate(df['Texto_limpo'][:total_epocas], 1):  # Começando em 1 para contar as épocas a partir de 1\n",
        "\n",
        "    # Tokenizar o texto\n",
        "    inputs = tokenizer(texto_limpo, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    inputs = {key: tensor.to(device) for key, tensor in inputs.items()}  # Enviar os inputs para o dispositivo correto\n",
        "\n",
        "    # Passar os inputs pelo modelo\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs)  # Removido .to(device)\n",
        "\n",
        "    # Decodificar as previsões\n",
        "    texto_gerado = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Adicionar o texto gerado à lista\n",
        "    textos_gerados.append(texto_gerado)\n",
        "\n",
        "    # Adicionar o número da época à lista\n",
        "    epocas.append(i)\n",
        "\n",
        "    # Imprimir o texto gerado e o número da época\n",
        "    print()\n",
        "    print(f\"Época {i} de {total_epocas} - Texto Gerado:\", texto_gerado)\n",
        "    print()"
      ],
      "metadata": {
        "id": "yZdZ06o_EZK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Limitar o DataFrame ao número de textos gerados\n",
        "df = df.head(len(textos_gerados_limitados))"
      ],
      "metadata": {
        "id": "ugrjKRpuKLly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicionar os textos gerados limitados como uma nova coluna ao DataFrame\n",
        "df['Texto_gerado_LLM_Gemini'] = textos_gerados_limitados"
      ],
      "metadata": {
        "id": "Lx8fLrbjVLL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Texto_gerado_LLM_Gemini.head()"
      ],
      "metadata": {
        "id": "ooHfUAGtVMiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Pré-processamento dos dados\n",
        "textos_limpos = df['Texto_gerado_LLM_Gemini']"
      ],
      "metadata": {
        "id": "lyizpT1mK5uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Representação dos dados\n",
        "\n",
        "# Ajuste os parâmetros conforme necessário\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "# Treinamento\n",
        "x_train = vectorizer.fit_transform(textos_limpos)\n",
        "\n",
        "# Visualizando\n",
        "vectorizer"
      ],
      "metadata": {
        "id": "KDvt4OFiK5xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Calcular a inércia para diferentes números de clusters\n",
        "inertia = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
        "    kmeans.fit(x_train)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Plotar a curva de cotovelo (elbow)\n",
        "plt.plot(range(1, 11), inertia, marker='o')\n",
        "plt.xlabel('Número de Clusters')\n",
        "plt.ylabel('Inércia')\n",
        "plt.title('Método do Cotovelo para Determinar Número de Clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AxRDk09GLG2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escolher o número de clusters\n",
        "# Defina o número de clusters com base no método do cotovelo\n",
        "num_clusters = 5"
      ],
      "metadata": {
        "id": "mxlP7q98LM4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Modelagem de clusterização\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)  # Defina o número de clusters\n",
        "kmeans.fit(x_train)"
      ],
      "metadata": {
        "id": "LyIpARSPK5z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# 4. Avaliação dos clusters\n",
        "silhouette_avg = silhouette_score(x_train, kmeans.labels_)\n",
        "print(\"Silhouette Score:\", silhouette_avg)"
      ],
      "metadata": {
        "id": "UAFuIpcTK52y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Interpretação dos clusters\n",
        "df['Cluster_LLM'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "s68Pm6GkK55b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.groupby('Cluster_LLM').size())"
      ],
      "metadata": {
        "id": "cVnEJ5QwVtwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando biblioteca\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Definir a perplexidade desejada\n",
        "#perplexidade = 35\n",
        "\n",
        "# Reduzir a dimensionalidade dos dados usando t-SNE\n",
        "tsne = TSNE(n_components=3, init='random', random_state=42)\n",
        "\n",
        "# Treinamento modelo\n",
        "X_tsne = tsne.fit_transform(x_train)\n",
        "\n",
        "# Reduzir a dimensionalidade dos dados usando TruncatedSVD\n",
        "svd = TruncatedSVD(n_components=3)\n",
        "\n",
        "# Treinamento modelo\n",
        "X_svd = svd.fit_transform(x_train)\n",
        "\n",
        "# Visualizando modelo\n",
        "tsne"
      ],
      "metadata": {
        "id": "w92Sdz06WQEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando modelo\n",
        "svd"
      ],
      "metadata": {
        "id": "3BebPs1SZRDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapear os rótulos de cluster para os sentimentos correspondentes\n",
        "cluster_sentimentos = {0:\n",
        "                       'Negativo', 1:\n",
        "                       'Neutro', 2:\n",
        "                       'Positivo'}\n",
        "\n",
        "# Criar subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Plotar gráfico de dispersão com os clusters após TruncatedSVD\n",
        "scatter_svd = sns.scatterplot(x=X_svd[:, 0], y=X_svd[:, 1], hue=kmeans.labels_, palette='bright', alpha=0.5, ax=axs[0])\n",
        "axs[0].set_title('Clusters TruncatedSVD LLM - Gemini')\n",
        "axs[0].set_xlabel('Componente Principal 1')\n",
        "axs[0].set_ylabel('Componente Principal 2')\n",
        "scatter_svd.legend(title='Cluster LLM', labels=[cluster_sentimentos[i] for i in range(len(cluster_sentimentos))])  # Adicionando legenda\n",
        "\n",
        "# Plotar gráfico de dispersão com os clusters após t-SNE\n",
        "scatter_tsne = sns.scatterplot(x=X_tsne[:, 0], y=X_tsne[:, 1], hue=kmeans.labels_, palette='bright', alpha=0.5, ax=axs[1])\n",
        "axs[1].set_title(f'Clusters t-SNE LLM - Gemini (Perplexidade={perplexidade})')\n",
        "axs[1].set_xlabel('Componente 1 (t-SNE)')\n",
        "axs[1].set_ylabel('Componente 2 (t-SNE)')\n",
        "scatter_tsne.legend(title='Cluster LLM', labels=[cluster_sentimentos[i] for i in range(len(cluster_sentimentos))])  # Adicionando legenda\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DiLinZ3tXUbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvando dataset\n",
        "df.to_csv('dataset_final.csv', index=False)"
      ],
      "metadata": {
        "id": "YZ1vnkIQK6Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvando dataset\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "# Supondo que 'model' é o seu modelo LLM\n",
        "model.save_pretrained(\"caminho/para/salvar/o/modelo\")"
      ],
      "metadata": {
        "id": "J_-IIPw2K6Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvando modelo\n",
        "model.save_pretrained(\"meu_modelo_gemini\")"
      ],
      "metadata": {
        "id": "_fT3LiDmK6NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy"
      ],
      "metadata": {
        "id": "bJl5vTg4aIJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "# Carregando modelo\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/meu_modelo_gemini\")"
      ],
      "metadata": {
        "id": "GWIrD3cLaQ2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"meu_modelo_gemini\")"
      ],
      "metadata": {
        "id": "n7KcFguoaTTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerar texto\n",
        "input_text = \"A inteligência artificial\"\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "output = model.generate(input_ids, max_length=100, num_return_sequences=1, temperature=0.9)\n",
        "\n",
        "# Decodificar e imprimir o texto gerado\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(\"Texto gerado:\", generated_text)"
      ],
      "metadata": {
        "id": "u0sYhNa5aaX-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}